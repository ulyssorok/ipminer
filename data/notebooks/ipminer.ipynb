{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "# Installing necessary libraries\n",
    "!pip3 install PyPDF2 nltk\n",
    "\n",
    "# Importing libraries\n",
    "import os\n",
    "import PyPDF2\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Downloading NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Function to convert PDF to plain text\n",
    "def pdf_to_text(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = ''\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "# Function to clean and tokenize text\n",
    "def clean_and_tokenize(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Tokenize into words\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stopwords and punctuation\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "# Directory containing research papers (PDF files)\n",
    "papers_directory = 'research/'\n",
    "\n",
    "# List to store preprocessed text\n",
    "preprocessed_text = []\n",
    "\n",
    "# Iterate over research papers\n",
    "for filename in os.listdir(papers_directory):\n",
    "    if filename.endswith('.pdf'):\n",
    "        file_path = os.path.join(papers_directory, filename)\n",
    "        # Convert PDF to plain text\n",
    "        text = pdf_to_text(file_path)\n",
    "        # Clean and tokenize text\n",
    "        tokens = clean_and_tokenize(text)\n",
    "        # Append preprocessed text to the list\n",
    "        preprocessed_text.append(tokens)\n",
    "\n",
    "print(\"Data Preprocessing completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm Preprocessing Results\n",
    "\n",
    "print(f\"Number of preprocessed documents: {len(preprocessed_text)}\")\n",
    "print(\"\\nSample preprocessed text:\")\n",
    "print(preprocessed_text[0][:50])  # Print the first 50 tokens of the first document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Named Entity Recognition (NER)\n",
    "\n",
    "# Installing necessary libraries\n",
    "!pip3 install spacy\n",
    "\n",
    "# Importing libraries\n",
    "import spacy\n",
    "\n",
    "# Loading the pre-trained NER model\n",
    "nlp = spacy.load(\"en_core_web_trf\")\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Function to perform NER on preprocessed text\n",
    "def perform_ner(text):\n",
    "    doc = nlp(\" \".join(text))\n",
    "    entities = []\n",
    "    for ent in doc.ents:\n",
    "        entities.append((ent.text, ent.label_))\n",
    "    return entities\n",
    "\n",
    "# Applying NER to preprocessed text\n",
    "entities_list = []\n",
    "for text in preprocessed_text:\n",
    "    entities = perform_ner(text)\n",
    "    entities_list.append(entities)\n",
    "\n",
    "# Printing the extracted entities for each document\n",
    "for i, entities in enumerate(entities_list):\n",
    "    print(f\"Document {i+1} entities:\")\n",
    "    for entity in entities:\n",
    "        print(f\"- {entity[0]} ({entity[1]})\")\n",
    "    print()\n",
    "\n",
    "print(\"Named Entity Recognition completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
